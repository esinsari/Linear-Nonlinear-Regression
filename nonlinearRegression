import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
from mpl_toolkits import mplot3d

# Preprocess input data and generate plots
data = pd.read_csv('data_nonlinear.csv')
X = data.iloc[:, 0]
Y = data.iloc[:, 1]
plt.scatter(X, Y)
plt.show()


# Build the model here
# y = bx + c --> y = ax^2 + bx + c
a = 0  # quadratic
b = 0  # bias
c = 0  # weight

L = 0.0001  #learning rate
epochs = 10000  #the number of iterations to perform gradient descent

n = float(len(X)) # Number of elements in X

print(float(len(X)))
print(float(len(Y)))

# Performing Gradient Descent 
for i in range(epochs):
    Y_pred = a*X**2 + b*X + c  # The current predicted value of Y
    D_A = (-2/n) * sum(X*X * (Y - Y_pred))  # Derivative wrt a
    D_B = (-2/n) * sum(X * (Y - Y_pred))  # Derivative wrt b
    D_C = (-2/n) * sum(Y - Y_pred)        # Derivative wrt c
    a = a - (L * D_A)  # Update a
    b = b - (L * D_B)  # Update b
    c = c - (L * D_C)  # Update c
    print(a, b,c)

print("Optimal Solution: ")
print (a, b, c)


# Generate prediction graphs 
Y_pred = a*X**2 + b*X + c

plt.scatter(X, Y)
plt.scatter(X, Y_pred) # predicted
#plt.plot([min(X), max(X)], [Y_pred[np.argmin(X)], Y_pred[np.argmax(X)]], color='red') # predicted
plt.show()
